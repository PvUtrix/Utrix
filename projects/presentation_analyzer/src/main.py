"""
Presentation Analyzer - Main Module
–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π –∏–∑ Google Drive
"""

import os
import logging
import yaml
from datetime import datetime
from typing import List, Dict, Optional
from pathlib import Path

from connectors.google_drive import GoogleDriveConnector
from processors.text_extractor import TextExtractor

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/presentation_analyzer.log'),
        logging.StreamHandler()
    ]
)

logger = logging.getLogger(__name__)

class PresentationAnalyzer:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π"""
    
    def __init__(self, config_path: str = "config/settings.yaml"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π
        
        Args:
            config_path: –ü—É—Ç—å –∫ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        self.config = self._load_config(config_path)
        self.drive_connector = None
        self.text_extractor = None
        self._initialize_components()
    
    def _load_config(self, config_path: str) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        try:
            with open(config_path, 'r', encoding='utf-8') as file:
                config = yaml.safe_load(file)
            logger.info("–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            return config
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
            raise
    
    def _initialize_components(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Google Drive –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä–∞
            credentials_path = self.config['google_drive']['credentials_path']
            folder_id = self.config['google_drive']['folder_id']
            
            if folder_id == "YOUR_FOLDER_ID_HERE":
                logger.warning("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∫–∞–∑–∞—Ç—å ID –ø–∞–ø–∫–∏ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏")
                return
            
            self.drive_connector = GoogleDriveConnector(credentials_path, folder_id)
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ —Ç–µ–∫—Å—Ç–∞
            ocr_enabled = self.config['processing']['ocr_enabled']
            language = self.config['processing']['language']
            self.text_extractor = TextExtractor(ocr_enabled, language)
            
            logger.info("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
            raise
    
    def sync_presentations(self) -> List[Dict]:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π –∏–∑ Google Drive
        
        Returns:
            –°–ø–∏—Å–æ–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
        """
        if not self.drive_connector:
            logger.error("Google Drive –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return []
        
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π
            file_types = self.config['google_drive']['file_types']
            presentations = self.drive_connector.list_presentations(file_types)
            
            if not presentations:
                logger.info("–ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
                return []
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π
            raw_data_path = self.config['storage']['raw_data_path']
            os.makedirs(raw_data_path, exist_ok=True)
            
            downloaded_files = []
            
            for presentation in presentations:
                file_id = presentation['id']
                file_name = presentation['name']
                
                # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è —Ñ–∞–π–ª–∞
                if presentation['mimeType'] == 'application/vnd.google-apps.presentation':
                    output_name = f"{file_name}.pdf"
                else:
                    output_name = file_name
                
                output_path = os.path.join(raw_data_path, output_name)
                
                # –°–∫–∞—á–∏–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
                if self.drive_connector.download_file(file_id, file_name, output_path):
                    downloaded_files.append({
                        'file_id': file_id,
                        'file_name': file_name,
                        'local_path': output_path,
                        'metadata': presentation
                    })
                    logger.info(f"–°–∫–∞—á–∞–Ω —Ñ–∞–π–ª: {file_name}")
                else:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å: {file_name}")
            
            logger.info(f"–°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(downloaded_files)}")
            return downloaded_files
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {e}")
            return []
    
    def process_all(self) -> List[Dict]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —Å–∫–∞—á–∞–Ω–Ω—ã—Ö –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        if not self.text_extractor:
            logger.error("–≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            return []
        
        raw_data_path = self.config['storage']['raw_data_path']
        processed_data_path = self.config['storage']['processed_data_path']
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        os.makedirs(processed_data_path, exist_ok=True)
        
        results = []
        
        # –ü–æ–∏—Å–∫ –≤—Å–µ—Ö PDF —Ñ–∞–π–ª–æ–≤
        pdf_files = list(Path(raw_data_path).glob("*.pdf"))
        
        for pdf_file in pdf_files:
            try:
                logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {pdf_file.name}")
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
                text_data = self.text_extractor.extract_text_from_pdf(str(pdf_file))
                
                if text_data['full_text']:
                    # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
                    cleaned_text = self.text_extractor.clean_text(text_data['full_text'])
                    
                    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
                    keywords = self.text_extractor.extract_keywords(
                        cleaned_text, 
                        self.config['text_processing']['max_keywords_per_doc']
                    )
                    
                    # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è
                    summary = self.text_extractor.generate_summary(cleaned_text)
                    
                    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    result = {
                        'file_name': pdf_file.name,
                        'file_path': str(pdf_file),
                        'processed_at': datetime.now().isoformat(),
                        'total_pages': text_data['total_pages'],
                        'word_count': len(cleaned_text.split()),
                        'extraction_method': text_data['extraction_method'],
                        'ocr_used': text_data['ocr_used'],
                        'keywords': keywords,
                        'summary': summary,
                        'full_text': cleaned_text,
                        'pages': text_data['pages']
                    }
                    
                    results.append(result)
                    
                    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                    self._save_processed_data(result, processed_data_path)
                    
                    logger.info(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {pdf_file.name}")
                else:
                    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç –∏–∑: {pdf_file.name}")
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {pdf_file.name}: {e}")
        
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(results)}")
        return results
    
    def _save_processed_data(self, result: Dict, output_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –°–æ–∑–¥–∞–Ω–∏–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
            base_name = Path(result['file_name']).stem
            output_file = Path(output_path) / f"{base_name}_processed.json"
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ JSON
            import json
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            
            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {output_file}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
    
    def integrate_with_knowledge_base(self, results: List[Dict]):
        """
        –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π
        
        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π
        """
        if not self.config['integration']['auto_tagging']:
            return
        
        knowledge_path = self.config['integration']['knowledge_base_path']
        os.makedirs(knowledge_path, exist_ok=True)
        
        for result in results:
            try:
                # –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏ –¥–ª—è –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏
                note_content = self._create_knowledge_note(result)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏
                note_filename = f"{Path(result['file_name']).stem}_notes.md"
                note_path = Path(knowledge_path) / note_filename
                
                with open(note_path, 'w', encoding='utf-8') as f:
                    f.write(note_content)
                
                logger.info(f"–°–æ–∑–¥–∞–Ω–∞ –∑–∞–º–µ—Ç–∫–∞: {note_path}")
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∑–∞–º–µ—Ç–∫–∏: {e}")
    
    def _create_knowledge_note(self, result: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–º–µ—Ç–∫–∏ –¥–ª—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π"""
        note_content = f"""# {result['file_name']}

## üìä –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
- **–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:** {result['processed_at']}
- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–∞–Ω–∏—Ü:** {result['total_pages']}
- **–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤:** {result['word_count']}
- **–ú–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è:** {result['extraction_method']}
- **OCR –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω:** {'–î–∞' if result['ocr_used'] else '–ù–µ—Ç'}

## üîë –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
{', '.join(result['keywords'])}

## üìù –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
{result['summary']}

## üìÑ –ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç
{result['full_text'][:1000]}...

---
*–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Å–æ–∑–¥–∞–Ω–æ —Å–∏—Å—Ç–µ–º–æ–π –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π*
"""
        return note_content
    
    def run_full_analysis(self) -> Dict:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π
        
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
        """
        logger.info("–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π")
        
        try:
            # –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏—è
            downloaded_files = self.sync_presentations()
            
            if not downloaded_files:
                logger.warning("–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
                return {'status': 'no_files'}
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞
            results = self.process_all()
            
            # –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π
            self.integrate_with_knowledge_base(results)
            
            # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            report = {
                'status': 'success',
                'downloaded_files': len(downloaded_files),
                'processed_files': len(results),
                'timestamp': datetime.now().isoformat(),
                'results': results
            }
            
            logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results)} —Ñ–∞–π–ª–æ–≤")
            return report
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return {'status': 'error', 'error': str(e)}


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    try:
        analyzer = PresentationAnalyzer()
        report = analyzer.run_full_analysis()
        
        if report['status'] == 'success':
            print(f"‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            print(f"üì• –°–∫–∞—á–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {report['downloaded_files']}")
            print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {report['processed_files']}")
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {report.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")
            
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")


if __name__ == "__main__":
    main()
